{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Two Sigma Financial Modelling Challenge](https://www.kaggle.com/c/two-sigma-financial-modeling)\n",
    "Can you uncover predictive value in an uncertain world? Hosted by [Kaggle](https://www.kaggle.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Here are all the modules we will be using in this notebook. Make sure you can import everything before moving on!'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('./src'))\n",
    "from model import *\n",
    "from transformer import *\n",
    "from observer import *\n",
    "from helpers import *\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "data_root = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__dyn_plot__ helps visualize the learning process dynamically. For details, read the answer by [HYRY](http://stackoverflow.com/users/772649/hyry):\n",
    "\n",
    "* [how to dynamically update a plot in a loop in ipython notebook within one cell](http://stackoverflow.com/questions/21360361/how-to-dynamically-update-a-plot-in-a-loop-in-ipython-notebook-within-one-cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def dyn_plot(history):\n",
    "#     plt.clf()\n",
    "#     plt.plot(history)\n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the training data into training, validation and test sets holding pairwise disjoint timestamps.\n",
    "These dataframes may share instruments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# raw_df = pd.read_hdf(data_root + 'train.h5')\n",
    "\n",
    "# num_time_stamps = len(raw_df['timestamp'].unique())\n",
    "# valid_start_ind = int(num_time_stamps * 0.5)\n",
    "# test_start_ind = int(num_time_stamps * 0.8)\n",
    "\n",
    "# raw_train_df = raw_df[raw_df['timestamp'] < valid_start_ind]\n",
    "# raw_valid_df = raw_df[(raw_df['timestamp'] < test_start_ind) & (raw_df['timestamp'] >= valid_start_ind)]\n",
    "# raw_test_df = raw_df[(raw_df['timestamp'] <= test_start_ind)]\n",
    "\n",
    "# raw_df = None # Release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# T = Transformer()\n",
    "# T.fit(raw_train_df)\n",
    "\n",
    "# train_df = T.transform(raw_train_df)\n",
    "# raw_train_df = None # Release Memory\n",
    "# print('processed training dataframe')\n",
    "\n",
    "# valid_df = T.transform(raw_valid_df)\n",
    "# raw_valid_df = None # Release Memory\n",
    "# print('processed validation dataframe')\n",
    "\n",
    "# test_df = T.transform(raw_test_df)\n",
    "# raw_test_df = None # Release Memory\n",
    "# print('processed test dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_df.to_hdf('./data/train_df.h5', key='train')\n",
    "# valid_df.to_hdf('./data/valid_df.h5', key='valid')\n",
    "# test_df.to_hdf('./data/test_df.h5', key='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_hdf('./data/train_df.h5', key='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Params\n",
    "# num_epoch = 40\n",
    "# batch_size = 128\n",
    "# num_feat = 109\n",
    "# lstm_size = 128 #1024\n",
    "# fc_hidd_size = 64 #256\n",
    "# lr = 1e-3\n",
    "\n",
    "# M = Model(num_feat=num_feat, lstm_size=lstm_size, fc_hidd_size=fc_hidd_size, lr=lr)\n",
    "# session = tf.Session()\n",
    "# session.run(tf.global_variables_initializer())\n",
    "    \n",
    "# history = []\n",
    "# for loss in M.fit(session, train_df, num_epoch, batch_size):\n",
    "#     history.append(loss)\n",
    "#     dyn_plot(np.sqrt(history))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
